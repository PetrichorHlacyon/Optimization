@article{2017ConvexitySmooth,
  title={MS&E 213 / CS 269O : Chapter 3- Convexity},
  author={Aaron Sidford},
  journal={},
  volume={},
  number={},
  pages={},



  
  year={2017},
}

@online{gormley2023introductiononlineconvexoptimization,
    title = {Introduction to Convex Optimization},
    author = {Matt Gormley},
    year = {2023},
    url = {https://www.cs.cmu.edu/~mgormley/courses/10425/},
    urldate      = {Use the date of acces}
}

@misc{hazan2023introductiononlineconvexoptimization,
      title={Introduction to Online Convex Optimization}, 
      author={Elad Hazan},
      year={2023},
      eprint={1909.05207},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1909.05207}, 
}

%%%%%%% Second Order Methods%%%%%%%%
@online{yudongchen2024nonlinearoptimization,
    title = {CS/ISyE/Math/Stat 726 Nonlinear Optimization I (Spring 2024)},
    author = {Yudong Chen},
    year = {2024},
    url = {https://pages.cs.wisc.edu/~yudongchen/cs726_sp24/},
    urldate      = {Use the date of acces}
}

@online{arora2004computationalmethodsforunconstrainedminimization,
    title = {COMPUTATIONAL METHODS FOR UNCONSTRAINED MINIMIZATION },
    author = {J. S. Arora},
    year = {2004},
    url = {https://user.engineering.uiowa.edu/~design1/53-235%20AOD/},
    urldate      = {Use the date of acces}
}


@InProceedings{pmlr-v2-schraudolph07a,
  title = 	 {A Stochastic Quasi-Newton Method for Online Convex Optimization},
  author = 	 {Schraudolph, Nicol N. and Yu, Jin and Günter, Simon},
  booktitle = 	 {Proceedings of the Eleventh International Conference on Artificial Intelligence and Statistics},
  pages = 	 {436--443},
  year = 	 {2007},
  editor = 	 {Meila, Marina and Shen, Xiaotong},
  volume = 	 {2},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {San Juan, Puerto Rico},
  month = 	 {21--24 Mar},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v2/schraudolph07a/schraudolph07a.pdf},
  url = 	 {https://proceedings.mlr.press/v2/schraudolph07a.html},
  abstract = 	 {We develop stochastic variants of the well-known BFGS quasi-Newton optimization method, in both full and memory-limited (LBFGS) forms, for online optimization of convex functions. The resulting algorithm performs comparably to a well-tuned natural gradient descent but is scalable to very high-dimensional problems. On standard benchmarks in natural language processing, it asymptotically outperforms previous stochastic gradient methods for parameter estimation in conditional random fields. We are working on analyzing the convergence of online (L)BFGS, and extending it to nonconvex optimization problems.}
}


%%%%%%%%%%%%Convexity and smoothness %%%%%%%%%%%%%%%
@online{aaron2017convexity,
    title = {MSandE213CS269O:Mathematical Optimization},
    author = {Aaron Sidford},
    year = {2017},
    url = {https://www.studocu.com/en-us/document/missouri-university-of-science-and-technology/convex-optimization/sidford-mse213-2019-fa-chap-1-intro/59892783?origin=university-course-page},
    urldate      = {Use the date of acces}
}


%%%%%%%%%%%%%%Derivative%%%%%%%%%%%%%%%%%%%%%%
@online{directionalderivatievesandthegradientvector,
    title = {Directional Derivatives and the Gradient Vector},
    author = {None},
    year = {None},
    url = {https://math.berkeley.edu/~arash/53/notes/14_6.pdf},
    urldate      = {Use the date of acces}
}

%%%%%%%%%%%%Online Optimization%%%%%%%%%%%%%%%%%%%
@online{anshitou2021banditzhishifenxiangyuzongjie,
    title = {bandit知识分享与总结},
    author = {安室透},
    year = {2021},
    url = {https://zhuanlan.zhihu.com/p/442717115},
    urldate      = {Use the date of acces}
}

%%%%%%%%%%%%%%%%%Gradient-based Method%%%%%%%%%%%%%%%%
@online{andersen2024projectedgradientalgorithm,
    title = {Projected Gradient Algorithm},
    author = {Andersen Ang},
    year = {2024},
    url = {https://angms.science/doc/CVX/CVX_PGD.pdf},
    urldate      = {Use the date of acces}
}

